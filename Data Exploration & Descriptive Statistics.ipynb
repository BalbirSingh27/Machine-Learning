{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "996a352b",
   "metadata": {},
   "source": [
    "# Decision Tree Model for Customer Satisfaction Prediction\n",
    "\n",
    "This notebook implements a decision tree model to predict customer satisfaction using the Santander Customer Satisfaction dataset. The following steps were taken:\n",
    "\n",
    "1. **Data Loading**:\n",
    "    - The training and test datasets are loaded using pandas.\n",
    "\n",
    "2. **Exploratory Data Analysis**:\n",
    "    - The first few rows of the dataset are displayed to understand its structure.\n",
    "    - Null values are counted to assess data quality.\n",
    "    - Summary statistics and information about the dataset are shown.\n",
    "    - Value counts of categorical features are printed for understanding feature distributions.\n",
    "    - A correlation matrix is computed to identify relationships between features and the target variable.\n",
    "\n",
    "3. **Feature Selection**:\n",
    "    - Highly correlated features with the target variable are identified to focus on important predictors.\n",
    "    - Features with low correlation (absolute value < 0.1) are also noted to potentially exclude irrelevant variables.\n",
    "\n",
    "4. **Model Training**:\n",
    "    - The data is split into training and validation sets (70% training and 30% validation).\n",
    "    - Several decision tree models are defined with varying hyperparameters for comparison.\n",
    "\n",
    "5. **Model Evaluation**:\n",
    "    - Each model is trained and evaluated using accuracy, F1 score, ROC AUC score, and confusion matrix.\n",
    "    - Results are stored and displayed to identify the best-performing model.\n",
    "\n",
    "6. **Hyperparameter Tuning**:\n",
    "    - A grid search is performed to find the optimal hyperparameters for the best model based on ROC AUC score.\n",
    "\n",
    "7. **Model Training with Best Hyperparameters**:\n",
    "    - **Updating Parameters**: \n",
    "        - Models are redefined according to the suggested best hyperparameters.\n",
    "        - This includes adjusting `max_depth`, `criterion`, `class_weight`, and `min_samples_leaf` values.\n",
    "    - **Re-evaluation**:\n",
    "        - Each updated model is retrained and evaluated using accuracy, F1 score, and ROC AUC score.\n",
    "        - Results are stored to compare with the initial models.\n",
    "    - **CSV File Generation for Comparison**:\n",
    "        - A CSV file is generated containing predictions and performance metrics of models with tuned parameters for easy comparison.\n",
    "\n",
    "8. **Exploring Different Tuning Options**:\n",
    "    - Additional hyperparameter tuning and redefinition of models based on new suggested values.\n",
    "    - **CSV Generation for Second Comparison**:\n",
    "        - Another CSV file is generated for a third comparison, allowing us to assess differences in model performance with each round of tuning.\n",
    "\n",
    "9. **Final Evaluation**:\n",
    "    - The best hyperparameter-tuned model is evaluated, and its performance metrics are printed.\n",
    "    - A classification report is generated for detailed performance analysis.\n",
    "\n",
    "10. **Submission Generation**:\n",
    "    - A function is created to generate a submission file for the test dataset containing predicted probabilities for customer satisfaction.\n",
    "\n",
    "11. **Comparison of Results**:\n",
    "    - Results across initial models, first tuning, and second tuning are analyzed to conclude the best model and approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02591dc",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a0ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Import NumPy for numerical operations\n",
    "import pandas as pd # Import pandas for data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4dabb",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eb81ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test datasets\n",
    "train = pd.read_csv('C:\\\\Users\\\\ayush\\\\Downloads\\\\Santander Customer Satisfaction - TRAIN.csv')\n",
    "test = pd.read_csv('C:\\\\Users\\\\ayush\\\\Downloads\\\\Santander Customer Satisfaction - TEST-Without TARGET.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1b2bb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
      "0   1     2     23                 0.0                      0.0   \n",
      "1   3     2     34                 0.0                      0.0   \n",
      "2   4     2     23                 0.0                      0.0   \n",
      "3   8     2     37                 0.0                    195.0   \n",
      "4  10     2     39                 0.0                      0.0   \n",
      "\n",
      "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
      "0                      0.0                      0.0                      0.0   \n",
      "1                      0.0                      0.0                      0.0   \n",
      "2                      0.0                      0.0                      0.0   \n",
      "3                    195.0                      0.0                      0.0   \n",
      "4                      0.0                      0.0                      0.0   \n",
      "\n",
      "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
      "0                      0.0                      0.0  ...   \n",
      "1                      0.0                      0.0  ...   \n",
      "2                      0.0                      0.0  ...   \n",
      "3                      0.0                      0.0  ...   \n",
      "4                      0.0                      0.0  ...   \n",
      "\n",
      "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
      "0                      0.0                      0.0                     0.0   \n",
      "1                      0.0                      0.0                     0.0   \n",
      "2                      0.0                      0.0                     0.0   \n",
      "3                      0.0                      0.0                     0.0   \n",
      "4                      0.0                      0.0                     0.0   \n",
      "\n",
      "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
      "0                     0.0                      0.0                      0.0   \n",
      "1                     0.0                      0.0                      0.0   \n",
      "2                     0.0                      0.0                      0.0   \n",
      "3                     0.0                      0.0                      0.0   \n",
      "4                     0.0                      0.0                      0.0   \n",
      "\n",
      "   saldo_medio_var44_ult1  saldo_medio_var44_ult3       var38  TARGET  \n",
      "0                     0.0                     0.0   39205.170       0  \n",
      "1                     0.0                     0.0   49278.030       0  \n",
      "2                     0.0                     0.0   67333.770       0  \n",
      "3                     0.0                     0.0   64007.970       0  \n",
      "4                     0.0                     0.0  117310.979       0  \n",
      "\n",
      "[5 rows x 371 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the training dataset\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee18fbb8",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00657b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                         0\n",
      "var3                       0\n",
      "var15                      0\n",
      "imp_ent_var16_ult1         0\n",
      "imp_op_var39_comer_ult1    0\n",
      "                          ..\n",
      "saldo_medio_var44_hace3    0\n",
      "saldo_medio_var44_ult1     0\n",
      "saldo_medio_var44_ult3     0\n",
      "var38                      0\n",
      "TARGET                     0\n",
      "Length: 371, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count and display the number of null values in each column\n",
    "null_counts = train.isnull().sum()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c6a7516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display statistical summaries of the training dataset\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9b784ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20a52320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display value counts for categorical columns\n",
    "for col in train.select_dtypes(include=['object']).columns:\n",
    "    print(f\"Value counts for {col}:\")\n",
    "    print(train[col].value_counts())\n",
    "    print(\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1905bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 highly correlation with target\n",
      " ['var36', 'var15', 'ind_var8_0']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation matrix for the training dataset\n",
    "correlation = train.corr()\n",
    "target_corr = correlation[\"TARGET\"].sort_values(ascending=False)\n",
    "highly_correlated_features = target_corr.index[1:4] # Get the top 3 features correlated with TARGET\n",
    "print(\"3 highly correlation with target\\n\", highly_correlated_features.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "932da14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 irrelevant variables:\n",
      " ['num_var4', 'num_var35', 'ind_var13']\n"
     ]
    }
   ],
   "source": [
    "target_corr = correlation[\"TARGET\"].sort_values(ascending=True)\n",
    "\n",
    "# Identify variables with low correlation (absolute value < 0.1)\n",
    "low_corr_features = target_corr[abs(target_corr) < 0.1].index.tolist()\n",
    "\n",
    "# Limit to three irrelevant features if there are more than three\n",
    "irrelevant_features = low_corr_features[:3]  # Get the first three irrelevant features\n",
    "\n",
    "print(\"3 irrelevant variables:\\n\", irrelevant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2264ac",
   "metadata": {},
   "source": [
    "## Model Training and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36d01298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import DecisionTreeClassifier for modeling\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV # Import functions for splitting data and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47fb9ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable for modeling\n",
    "X = train.drop(columns=[\"TARGET\"]) # Features (input data)\n",
    "y = train[\"TARGET\"] # Target variable (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f065e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets (70% train, 30% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ffc5b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Decision Tree model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train) # Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "291f82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from the trained model\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"feature\":X.columns,\n",
    "    \"importance\":model.feature_importances_\n",
    "}).sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "004f4c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Important Features:\n",
      " ['ID', 'var38', 'var15']\n"
     ]
    }
   ],
   "source": [
    "# Get the top 3 most important features\n",
    "most_important_features = feature_importances[\"feature\"].head(3).tolist()\n",
    "print(\"Top Important Features:\\n\", most_important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73358017",
   "metadata": {},
   "source": [
    "## Model Evaluation - Comparing Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b4e3280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple models with different hyperparameters for comparison\n",
    "models = {\n",
    "    \"Model 1\": DecisionTreeClassifier(max_depth=5, criterion=\"gini\", min_samples_leaf=5),\n",
    "    \"Model 2\": DecisionTreeClassifier(max_depth=10, criterion=\"gini\", min_samples_leaf=10),\n",
    "    \"Model 3\": DecisionTreeClassifier(max_depth=None, criterion=\"entropy\", min_samples_leaf=20),\n",
    "    \"Model 4\": DecisionTreeClassifier(max_depth=10, criterion=\"entropy\", min_samples_leaf=10),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcebc85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metrics for evaluation\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e62a3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "# Iterate over each model, fit it, and evaluate its performance\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train) # Fit model on training data\n",
    "    val_predictions = model.predict(X_val) # Make predictions on validation data\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_val, val_predictions)\n",
    "    f1 = f1_score(y_val, val_predictions)\n",
    "    roc_auc = roc_auc_score(y_val, model.predict_proba(X_val)[:, 1])\n",
    "    confusion = confusion_matrix(y_val, val_predictions)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1 Score\": f1,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"Confusion Matrix\": confusion\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5101f88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Model  Accuracy  F1 Score   ROC AUC          Confusion Matrix\n",
      "0  Model 1  0.959835  0.000000  0.807686    [[21890, 1], [915, 0]]\n",
      "1  Model 2  0.958037  0.018462  0.779357   [[21840, 51], [906, 9]]\n",
      "2  Model 3  0.957292  0.058027  0.705577  [[21802, 89], [885, 30]]\n",
      "3  Model 4  0.958257  0.016529  0.775468   [[21846, 45], [907, 8]]\n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44855c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: Model 1\n"
     ]
    }
   ],
   "source": [
    "# Identify the best model based on ROC AUC score\n",
    "best_model_name = results_df.loc[results_df['ROC AUC'].idxmax()]['Model']\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nBest Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3478ebe",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6d42aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=DecisionTreeClassifier(max_depth=5, min_samples_leaf=5),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 5, 10, 15],\n",
       "                         'min_samples_split': [2, 5, 10]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter tuning using Grid Search for the best model\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(best_model, param_grid, scoring='roc_auc', cv=5) # Define grid search\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdbd356",
   "metadata": {},
   "source": [
    "## Evaluation of Best Hyperparameter-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0725697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Model 1: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10}\n",
      "\n",
      "Best Hyperparameter-Tuned Model Accuracy: 0.9597\n",
      "Best Hyperparameter-Tuned Model F1 Score: 0.0000\n",
      "Best Hyperparameter-Tuned Model ROC AUC Score: 0.8002\n",
      "Best Hyperparameter-Tuned Model Confusion Matrix:\n",
      "[[21887     4]\n",
      " [  915     0]]\n",
      "Best Hyperparameter-Tuned Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     21891\n",
      "           1       0.00      0.00      0.00       915\n",
      "\n",
      "    accuracy                           0.96     22806\n",
      "   macro avg       0.48      0.50      0.49     22806\n",
      "weighted avg       0.92      0.96      0.94     22806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Best model from Grid Search\n",
    "best_hyper_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Hyperparameters for {best_model_name}: {best_params}\")\n",
    "\n",
    "# Evaluate the best model\n",
    "best_val_predictions = best_hyper_model.predict(X_val)\n",
    "\n",
    "# Calculate metrics for the best hyperparameter-tuned model\n",
    "best_accuracy = accuracy_score(y_val, best_val_predictions)\n",
    "best_f1 = f1_score(y_val, best_val_predictions)\n",
    "best_roc_auc = roc_auc_score(y_val, best_hyper_model.predict_proba(X_val)[:, 1])\n",
    "best_confusion = confusion_matrix(y_val, best_val_predictions)\n",
    "\n",
    "# Print evaluation metrics for the best hyperparameter-tuned model\n",
    "print(f\"\\nBest Hyperparameter-Tuned Model Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Best Hyperparameter-Tuned Model F1 Score: {best_f1:.4f}\")\n",
    "print(f\"Best Hyperparameter-Tuned Model ROC AUC Score: {best_roc_auc:.4f}\")\n",
    "print(\"Best Hyperparameter-Tuned Model Confusion Matrix:\")\n",
    "print(best_confusion)\n",
    "print(\"Best Hyperparameter-Tuned Model Classification Report:\")\n",
    "print(classification_report(y_val, best_val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db494e23",
   "metadata": {},
   "source": [
    "## Submission File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0be887e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Function to generate submission file for the test dataset\n",
    "def generate_submission(model, test_df, features):\n",
    "    predictions = model.predict_proba(test_df[features])[:, 1]\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_df['ID'],\n",
    "        'TARGET': predictions\n",
    "    })\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(\"Submission file created: submission.csv\")\n",
    "# Generate the submission file\n",
    "generate_submission(best_hyper_model, test, X.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7187dad",
   "metadata": {},
   "source": [
    "## Model Training with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20f39c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the parameters of the models according to the suggested best hyperparameters\n",
    "models = {\n",
    "    \"Model 1\": DecisionTreeClassifier(max_depth=5, criterion=\"entropy\",class_weight='balanced', min_samples_leaf=2),\n",
    "    \"Model 2\": DecisionTreeClassifier(max_depth=10, criterion=\"gini\", min_samples_leaf=10),\n",
    "    \"Model 3\": DecisionTreeClassifier(max_depth=None, criterion=\"entropy\", min_samples_leaf=20),\n",
    "    \"Model 4\": DecisionTreeClassifier(max_depth=10, criterion=\"entropy\", min_samples_leaf=10),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c67dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    val_predictions = model.predict(X_val)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_val, val_predictions)\n",
    "    f1 = f1_score(y_val, val_predictions)\n",
    "    roc_auc = roc_auc_score(y_val, model.predict_proba(X_val)[:, 1])\n",
    "    confusion = confusion_matrix(y_val, val_predictions)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1 Score\": f1,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"Confusion Matrix\": confusion\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff979fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Model  Accuracy  F1 Score   ROC AUC             Confusion Matrix\n",
      "0  Model 1  0.734544  0.179675  0.799795  [[16089, 5802], [252, 663]]\n",
      "1  Model 2  0.958037  0.018462  0.780172      [[21840, 51], [906, 9]]\n",
      "2  Model 3  0.957467  0.060078  0.705046     [[21805, 86], [884, 31]]\n",
      "3  Model 4  0.958213  0.014478  0.776497      [[21846, 45], [908, 7]]\n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e473b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: Model 1\n"
     ]
    }
   ],
   "source": [
    "# Identify the best model based on ROC AUC score\n",
    "best_model_name = results_df.loc[results_df['ROC AUC'].idxmax()]['Model']\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nBest Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8cab4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=DecisionTreeClassifier(class_weight='balanced',\n",
       "                                              criterion='entropy', max_depth=5,\n",
       "                                              min_samples_leaf=2),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 5, 10, 15],\n",
       "                         'min_samples_split': [2, 5, 10]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter tuning using Grid Search for the best model\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(best_model, param_grid, scoring='roc_auc', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2b8bf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Model 1: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}\n",
      "\n",
      "Best Hyperparameter-Tuned Model Accuracy: 0.7345\n",
      "Best Hyperparameter-Tuned Model F1 Score: 0.1797\n",
      "Best Hyperparameter-Tuned Model ROC AUC Score: 0.7998\n",
      "Best Hyperparameter-Tuned Model Confusion Matrix:\n",
      "[[16089  5802]\n",
      " [  252   663]]\n",
      "Best Hyperparameter-Tuned Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.73      0.84     21891\n",
      "           1       0.10      0.72      0.18       915\n",
      "\n",
      "    accuracy                           0.73     22806\n",
      "   macro avg       0.54      0.73      0.51     22806\n",
      "weighted avg       0.95      0.73      0.82     22806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Best model from Grid Search\n",
    "best_hyper_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Hyperparameters for {best_model_name}: {best_params}\")\n",
    "\n",
    "# Evaluate the best model\n",
    "best_val_predictions = best_hyper_model.predict(X_val)\n",
    "\n",
    "# Calculate metrics for the best hyperparameter-tuned model\n",
    "best_accuracy = accuracy_score(y_val, best_val_predictions)\n",
    "best_f1 = f1_score(y_val, best_val_predictions)\n",
    "best_roc_auc = roc_auc_score(y_val, best_hyper_model.predict_proba(X_val)[:, 1])\n",
    "best_confusion = confusion_matrix(y_val, best_val_predictions)\n",
    "\n",
    "# Print evaluation metrics for the best hyperparameter-tuned model\n",
    "print(f\"\\nBest Hyperparameter-Tuned Model Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Best Hyperparameter-Tuned Model F1 Score: {best_f1:.4f}\")\n",
    "print(f\"Best Hyperparameter-Tuned Model ROC AUC Score: {best_roc_auc:.4f}\")\n",
    "print(\"Best Hyperparameter-Tuned Model Confusion Matrix:\")\n",
    "print(best_confusion)\n",
    "print(\"Best Hyperparameter-Tuned Model Classification Report:\")\n",
    "print(classification_report(y_val, best_val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "714dd87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Function to generate submission file for the test dataset\n",
    "def generate_submission(model, test_df, features):\n",
    "    predictions = model.predict_proba(test_df[features])[:, 1]\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_df['ID'],\n",
    "        'TARGET': predictions\n",
    "    })\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(\"Submission file created: submission.csv\")\n",
    "# Generate the submission file\n",
    "generate_submission(best_hyper_model, test, X.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2511b82c",
   "metadata": {},
   "source": [
    "## Model Training with Different Hyperparameters to Explore Different Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ab04b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the parameters to get different results to explore the results\n",
    "models = {\n",
    "    \"Model 1\": DecisionTreeClassifier(max_depth=5, criterion=\"entropy\",class_weight='balanced', min_samples_leaf=5),\n",
    "    \"Model 2\": DecisionTreeClassifier(max_depth=2, criterion=\"gini\", min_samples_leaf=10),\n",
    "    \"Model 3\": DecisionTreeClassifier(max_depth=10, criterion=\"entropy\", min_samples_leaf=20),\n",
    "    \"Model 4\": DecisionTreeClassifier(max_depth=5, criterion=\"gini\",class_weight='balanced', min_samples_leaf=10),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d79a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    val_predictions = model.predict(X_val)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_val, val_predictions)\n",
    "    f1 = f1_score(y_val, val_predictions)\n",
    "    roc_auc = roc_auc_score(y_val, model.predict_proba(X_val)[:, 1])\n",
    "    confusion = confusion_matrix(y_val, val_predictions)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1 Score\": f1,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"Confusion Matrix\": confusion\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f51fde4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Model  Accuracy  F1 Score   ROC AUC             Confusion Matrix\n",
      "0  Model 1  0.734544  0.179675  0.799795  [[16089, 5802], [252, 663]]\n",
      "1  Model 2  0.959879  0.000000  0.765357       [[21891, 0], [915, 0]]\n",
      "2  Model 3  0.959397  0.004301  0.777571      [[21878, 13], [913, 2]]\n",
      "3  Model 4  0.784136  0.203527  0.803696  [[17254, 4637], [286, 629]]\n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0a14cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: Model 4\n"
     ]
    }
   ],
   "source": [
    "# Identify the best model based on ROC AUC score\n",
    "best_model_name = results_df.loc[results_df['ROC AUC'].idxmax()]['Model']\n",
    "best_model = models[best_model_name]\n",
    "print(f\"\\nBest Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d15780da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=DecisionTreeClassifier(class_weight='balanced',\n",
       "                                              max_depth=5,\n",
       "                                              min_samples_leaf=10),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 5, 10, 15],\n",
       "                         'min_samples_split': [2, 5, 10]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter tuning using Grid Search for the best model\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(best_model, param_grid, scoring='roc_auc', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d71b099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Model 4: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}\n",
      "\n",
      "Best Hyperparameter-Tuned Model Accuracy: 0.7345\n",
      "Best Hyperparameter-Tuned Model F1 Score: 0.1797\n",
      "Best Hyperparameter-Tuned Model ROC AUC Score: 0.7998\n",
      "Best Hyperparameter-Tuned Model Confusion Matrix:\n",
      "[[16089  5802]\n",
      " [  252   663]]\n",
      "Best Hyperparameter-Tuned Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.73      0.84     21891\n",
      "           1       0.10      0.72      0.18       915\n",
      "\n",
      "    accuracy                           0.73     22806\n",
      "   macro avg       0.54      0.73      0.51     22806\n",
      "weighted avg       0.95      0.73      0.82     22806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Best model from Grid Search\n",
    "best_hyper_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Hyperparameters for {best_model_name}: {best_params}\")\n",
    "\n",
    "# Evaluate the best model\n",
    "best_val_predictions = best_hyper_model.predict(X_val)\n",
    "\n",
    "# Calculate metrics for the best hyperparameter-tuned model\n",
    "best_accuracy = accuracy_score(y_val, best_val_predictions)\n",
    "best_f1 = f1_score(y_val, best_val_predictions)\n",
    "best_roc_auc = roc_auc_score(y_val, best_hyper_model.predict_proba(X_val)[:, 1])\n",
    "best_confusion = confusion_matrix(y_val, best_val_predictions)\n",
    "\n",
    "# Print evaluation metrics for the best hyperparameter-tuned model\n",
    "print(f\"\\nBest Hyperparameter-Tuned Model Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Best Hyperparameter-Tuned Model F1 Score: {best_f1:.4f}\")\n",
    "print(f\"Best Hyperparameter-Tuned Model ROC AUC Score: {best_roc_auc:.4f}\")\n",
    "print(\"Best Hyperparameter-Tuned Model Confusion Matrix:\")\n",
    "print(best_confusion)\n",
    "print(\"Best Hyperparameter-Tuned Model Classification Report:\")\n",
    "print(classification_report(y_val, best_val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f324568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Function to generate submission file for the test dataset\n",
    "def generate_submission(model, test_df, features):\n",
    "    predictions = model.predict_proba(test_df[features])[:, 1]\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_df['ID'],\n",
    "        'TARGET': predictions\n",
    "    })\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(\"Submission file created: submission.csv\")\n",
    "# Generate the submission file\n",
    "generate_submission(best_hyper_model, test, X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113f763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
